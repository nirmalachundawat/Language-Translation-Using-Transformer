{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:43:43.906117Z","iopub.execute_input":"2024-09-22T10:43:43.906448Z","iopub.status.idle":"2024-09-22T10:43:59.343513Z","shell.execute_reply.started":"2024-09-22T10:43:43.906420Z","shell.execute_reply":"2024-09-22T10:43:59.342430Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay\nfrom transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:44:04.646859Z","iopub.execute_input":"2024-09-22T10:44:04.647846Z","iopub.status.idle":"2024-09-22T10:44:23.367585Z","shell.execute_reply.started":"2024-09-22T10:44:04.647810Z","shell.execute_reply":"2024-09-22T10:44:23.366659Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-09-22 10:44:10.517197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-22 10:44:10.517309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-22 10:44:10.652894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:00.810067Z","iopub.execute_input":"2024-09-22T10:45:00.811260Z","iopub.status.idle":"2024-09-22T10:45:00.815572Z","shell.execute_reply.started":"2024-09-22T10:45:00.811224Z","shell.execute_reply":"2024-09-22T10:45:00.814451Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:01.836432Z","iopub.execute_input":"2024-09-22T10:45:01.837095Z","iopub.status.idle":"2024-09-22T10:45:08.510559Z","shell.execute_reply.started":"2024-09-22T10:45:01.837061Z","shell.execute_reply":"2024-09-22T10:45:08.509655Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c4662b24604aabacf804dcaa8bd112"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464bac3f1520480ea2aecc1ad5205f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cb58903dd648a6acb9e709e38e39ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/85.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"718d3687f464489181d0ad155d7395e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9550bb5ed31e4d9caef109f091763171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baeb29ba613a43bfa3c557da75442ee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ac398892e046b993f4c06ede58b2dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7b9389e5ec4601bdb0ca67d400a960"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:17.646917Z","iopub.execute_input":"2024-09-22T10:45:17.648012Z","iopub.status.idle":"2024-09-22T10:45:17.654625Z","shell.execute_reply.started":"2024-09-22T10:45:17.647974Z","shell.execute_reply":"2024-09-22T10:45:17.653628Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1659083\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets['train'][1]","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:28.666630Z","iopub.execute_input":"2024-09-22T10:45:28.667074Z","iopub.status.idle":"2024-09-22T10:45:28.677495Z","shell.execute_reply.started":"2024-09-22T10:45:28.667026Z","shell.execute_reply":"2024-09-22T10:45:28.676453Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'Accerciser Accessibility Explorer',\n  'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'}}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:29.077822Z","iopub.execute_input":"2024-09-22T10:45:29.078226Z","iopub.status.idle":"2024-09-22T10:45:31.296949Z","shell.execute_reply.started":"2024-09-22T10:45:29.078198Z","shell.execute_reply":"2024-09-22T10:45:31.295765Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60f87e8cfc04ae58761d544a8ba62d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2bf5e9582b486fa804ca6a8d552cb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692d4d567ee044d6a02eb8dff9a8b00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7cf3928d89842df863539a01bbc24cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1367c3c191834c88b0d885b2c4724ada"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer(\"Hello, this is a sentence!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:36.247408Z","iopub.execute_input":"2024-09-22T10:45:36.248489Z","iopub.status.idle":"2024-09-22T10:45:36.254951Z","shell.execute_reply.started":"2024-09-22T10:45:36.248452Z","shell.execute_reply":"2024-09-22T10:45:36.254051Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [12110, 2, 90, 23, 19, 8800, 61, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer([\"Hello, this is a sentence!\", \"This is another sentence.\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:36.768372Z","iopub.execute_input":"2024-09-22T10:45:36.769480Z","iopub.status.idle":"2024-09-22T10:45:36.776607Z","shell.execute_reply.started":"2024-09-22T10:45:36.769437Z","shell.execute_reply":"2024-09-22T10:45:36.775650Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[12110, 2, 90, 23, 19, 8800, 61, 0], [239, 23, 414, 8800, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"एक्सेर्साइसर पहुंचनीयता अन्वेषक\"]))","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:37.806559Z","iopub.execute_input":"2024-09-22T10:45:37.807220Z","iopub.status.idle":"2024-09-22T10:45:37.816673Z","shell.execute_reply.started":"2024-09-22T10:45:37.807186Z","shell.execute_reply":"2024-09-22T10:45:37.815517Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'input_ids': [[26618, 16155, 346, 33383, 0]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\n\nsource_lang = \"en\"\ntarget_lang = \"hi\"\n\n\ndef preprocess_function(examples):\n    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:38.607335Z","iopub.execute_input":"2024-09-22T10:45:38.607775Z","iopub.status.idle":"2024-09-22T10:45:39.523453Z","shell.execute_reply.started":"2024-09-22T10:45:38.607745Z","shell.execute_reply":"2024-09-22T10:45:39.522406Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"preprocess_function(raw_datasets[\"train\"][:2])","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:50.307487Z","iopub.execute_input":"2024-09-22T10:45:50.308459Z","iopub.status.idle":"2024-09-22T10:45:50.316072Z","shell.execute_reply.started":"2024-09-22T10:45:50.308426Z","shell.execute_reply":"2024-09-22T10:45:50.315004Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:45:50.795883Z","iopub.execute_input":"2024-09-22T10:45:50.796306Z","iopub.status.idle":"2024-09-22T10:54:27.989170Z","shell.execute_reply.started":"2024-09-22T10:45:50.796279Z","shell.execute_reply":"2024-09-22T10:54:27.988260Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13f5140c9364c1f82c878c591f36027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7d15e8c0a941fa86e55b845f81354c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524895ed31de4aafa2faf43eb5c1f7a1"}},"metadata":{}}]},{"cell_type":"code","source":"model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:54:32.946384Z","iopub.execute_input":"2024-09-22T10:54:32.946764Z","iopub.status.idle":"2024-09-22T10:54:41.761990Z","shell.execute_reply.started":"2024-09-22T10:54:32.946736Z","shell.execute_reply":"2024-09-22T10:54:41.761104Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0edb43e8702d46c1af07016778b3f448"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e6916cc78542329b476c0712490fe1"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 2e-5\nweight_decay = 0.01\nnum_train_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:54:50.096214Z","iopub.execute_input":"2024-09-22T10:54:50.097052Z","iopub.status.idle":"2024-09-22T10:54:50.101380Z","shell.execute_reply.started":"2024-09-22T10:54:50.097019Z","shell.execute_reply":"2024-09-22T10:54:50.100327Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T10:54:55.656529Z","iopub.execute_input":"2024-09-22T10:54:55.656909Z","iopub.status.idle":"2024-09-22T10:54:55.661708Z","shell.execute_reply.started":"2024-09-22T10:54:55.656881Z","shell.execute_reply":"2024-09-22T10:54:55.660519Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:01:44.287841Z","iopub.execute_input":"2024-09-22T11:01:44.289001Z","iopub.status.idle":"2024-09-22T11:01:44.293596Z","shell.execute_reply.started":"2024-09-22T11:01:44.288955Z","shell.execute_reply":"2024-09-22T11:01:44.292598Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"train\"],\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:01:47.253921Z","iopub.execute_input":"2024-09-22T11:01:47.254860Z","iopub.status.idle":"2024-09-22T11:01:48.784889Z","shell.execute_reply.started":"2024-09-22T11:01:47.254825Z","shell.execute_reply":"2024-09-22T11:01:48.783861Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"validation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:01:54.546682Z","iopub.execute_input":"2024-09-22T11:01:54.547634Z","iopub.status.idle":"2024-09-22T11:01:54.719845Z","shell.execute_reply.started":"2024-09-22T11:01:54.547597Z","shell.execute_reply":"2024-09-22T11:01:54.718808Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"generation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size=8,\n    shuffle=False,\n    collate_fn=generation_data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:01:57.218034Z","iopub.execute_input":"2024-09-22T11:01:57.218934Z","iopub.status.idle":"2024-09-22T11:01:57.396544Z","shell.execute_reply.started":"2024-09-22T11:01:57.218886Z","shell.execute_reply":"2024-09-22T11:01:57.395756Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\nmodel.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:02:00.596464Z","iopub.execute_input":"2024-09-22T11:02:00.597355Z","iopub.status.idle":"2024-09-22T11:02:00.617143Z","shell.execute_reply.started":"2024-09-22T11:02:00.597318Z","shell.execute_reply":"2024-09-22T11:02:00.616071Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset, validation_data=validation_dataset, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:02:07.678376Z","iopub.execute_input":"2024-09-22T11:02:07.679092Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\nWARNING: AutoGraph could not transform <function infer_framework at 0x79b7a4ae8430> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n 13601/103692 [==>...........................] - ETA: 6:50:50 - loss: 2.7623","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":" 35707/103692 [=========>....................] - ETA: 5:09:45 - loss: 2.5372","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":" 44280/103692 [===========>..................] - ETA: 4:30:45 - loss: 2.4832","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":" 50428/103692 [=============>................] - ETA: 4:02:37 - loss: 2.4499","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":" 58194/103692 [===============>..............] - ETA: 3:27:03 - loss: 2.4131","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"tf_model/\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T09:15:57.530659Z","iopub.execute_input":"2024-08-17T09:15:57.531076Z","iopub.status.idle":"2024-08-17T09:15:58.625733Z","shell.execute_reply.started":"2024-08-17T09:15:57.531043Z","shell.execute_reply":"2024-08-17T09:15:58.624772Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T09:16:16.555256Z","iopub.execute_input":"2024-08-17T09:16:16.555665Z","iopub.status.idle":"2024-08-17T09:16:20.118941Z","shell.execute_reply.started":"2024-08-17T09:16:16.555615Z","shell.execute_reply":"2024-08-17T09:16:20.118074Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nAll model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at tf_model/.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text  = \"My name Bappy. My youtube channel name is DSwithBappy\"\n\ntokenized = tokenizer([input_text], return_tensors='np')\nout = model.generate(**tokenized, max_length=128)\nprint(out)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T09:16:31.415401Z","iopub.execute_input":"2024-08-17T09:16:31.415805Z","iopub.status.idle":"2024-08-17T09:16:40.255276Z","shell.execute_reply.started":"2024-08-17T09:16:31.415774Z","shell.execute_reply":"2024-08-17T09:16:40.254259Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[61949   500   179  4598 14918   130     5     2   500   118  3140  4186\n   4850   179     5    44     3   345  1275  1275   667   667     0 61949\n  61949 61949]], shape=(1, 26), dtype=int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer.decode(out[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-08-17T09:16:54.735504Z","iopub.execute_input":"2024-08-17T09:16:54.736006Z","iopub.status.idle":"2024-08-17T09:16:54.744629Z","shell.execute_reply.started":"2024-08-17T09:16:54.735973Z","shell.execute_reply":"2024-08-17T09:16:54.743608Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"मेरा नाम बाप्पी है, मेरा आपखबे चैनल नाम है.SBByy\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}